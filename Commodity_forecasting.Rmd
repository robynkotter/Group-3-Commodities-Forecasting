---
title: "Capstone_commodity_forecast"
Author: Nathan Garn
date: "2023-04-15"
output:
  html_document:
    highlight: breezedark
    number_sections: yes
    toc: yes
    fig_width: 15
    fig_height: 10
  '': default
---

# Business Problem
```{r}
# Swire is looking to forecast commodity costs to help with business strategy. They desire to strike a balance between higher sales with a lower product price, and pricing their product high enough for greater margins. Forecasting costs will help them plan for pricing in the future. Understanding commodity costs will also help Swire optimize its procurement strategy and inventory management. 
# The analysis will be successful if it accurately predicts price. High scores on the model accuracy for testing data will allow for confidence in the model. The project will be executed by our team. We are not only looking for an accurate model but a interactive dashboard that is easy for Swire to use. This would allow them to select individual elements of the prediction for customized observation. Any data found to help predictions could be added in the future. 
#An important part of Swire's business is understanding commodity pricing. It impacts production, margins, and business planning. Creating an accurate time-series forecast of price will help with strategy. Future planning is key for any business and the forecast will help with planning with their resources.

```

# Analytical Objective
```{r}
# The desired outcome would be a strong forecast model for commodity price. Some of the key metrics will be p-value, coefficients, AIC values and more. These metrics can be shared with stakeholders for them to understand the strength of the model as they use it. Multiple models will be created to view differences in prediction and metrics. After a analysis of the performance of each model, a deferment to the best model will be made. The ultimate object would be to build a prediction model that Swire can use to inform decisions for future planning. 


```


# Packages
```{r packages}
library(quantmod)
library(ggplot2)
library(forecast)
library(astsa)
library(tseries)
library(tidyverse)
library(caret)
library(bigrquery)
library(prophet)
library(lubridate)
library(openxlsx)
library(dplyr)
library(readr)
library(feasts)
library(tsibble)
library(Metrics)
library(rugarch)
library(rmgarch)

```

# Data Load
```{r}
coffee <- read.csv("Coffee_prices.csv", stringsAsFactors = FALSE)%>%
mutate(date = ymd(date))%>% 
mutate(month = format_ISO8601(date, precision = "ym"))

Aluminum <- read.csv("Aluminium_end_price.csv",stringsAsFactors = FALSE)%>%
mutate(date = ymd(date))%>% 
mutate(month = format_ISO8601(date, precision = "ym"))

sugar <- read.csv("sugar-prices-historical-chart-data.csv",stringsAsFactors = FALSE)%>%
mutate(date = mdy(date))%>% 
mutate(month = format_ISO8601(date, precision = "ym"))

soybean <- read.csv("soybean-prices-historical-chart-data.csv",stringsAsFactors = FALSE)%>%
mutate(date = ymd(date))%>% 
mutate(month = format_ISO8601(date, precision = "ym"))

soybeanoil <- read.csv("soybean-oil-prices-historical-chart-data.csv",stringsAsFactors = FALSE)%>%
mutate(date = ymd(date))%>% 
mutate(month = format_ISO8601(date, precision = "ym"))

corn <- read.csv("corn-prices-historical-chart-data.csv")%>%
mutate(date = ymd(date))%>% 
mutate(month = format_ISO8601(date, precision = "ym"))

cotton <- read.csv("cotton-prices-historical-chart-data.csv")%>%
mutate(date = ymd(date))%>% 
mutate(month = format_ISO8601(date, precision = "ym"))


```

# Exploring Sugar
```{r}

# Looking at the price of sugar over the last 30 years
ggplot(sugar, aes(date, price)) +
  geom_line() +
  labs(title = "Sugar Prices") + xlab("year") + ylab("prices")
  
#Summary of sugar
summary(sugar)
#Significant fluctuations in price.
  
#Sugar monthly average

sugar_m <- sugar %>% group_by(month) %>% mutate(mon_avg = mean(price))%>%
select(month, mon_avg)

#Drop Duplicate rows Sugar

sugar_m <- sugar_m[!duplicated(sugar_m),]

#Creating Time series data for Sugar

sugar_ts <- ts(sugar_m$mon_avg,start=c(1993),frequency=12)

#Plotting

chartSeries(sugar_ts)


#Looking at trends

autoplot(decompose((sugar_ts)),main="") 
#Price spikes occur between 2010-2012 and again in the 2020's

#Sugar Looking for daily or weekly trends

sugar_r <- sugar %>%
filter(date >= as.Date('2022-11-01') & date <= as.Date('2023-01-31'))

ggplot(sugar_r, aes(date, price)) +
  geom_line() +
  labs(title = "Sugar Prices Daily") + xlab("time") + ylab("prices")

# There does not appear to be trends by day of the week. 


#Sugar Prices Controlling for inflation

#write.csv(sugar_m, file="sugar_m.csv",row.names = FALSE)

sugar_CPI <- read.csv("Sugar_cpi.csv")

sugar_adj <- left_join(sugar_m, sugar_CPI, by = c("month" = "date"))

sugar_adj$adj_price <- sugar_adj$mon_avg / sugar_adj$Value

sugar_ts_adj <- ts(sugar_adj$adj_price, start = c(1993), frequency = 12)


ggplot(sugar, aes(date, price)) +
  geom_line() +
  labs(title = "Sugar Prices") + xlab("year") + ylab("prices")

 chartSeries(sugar_ts)

ggplot(data = sugar_adj, aes(x = month, y = adj_price, group = 1)) +
  geom_line() +
  labs(x = "Month", y = "Adjusted Sugar Price", title = "Sugar Prices Adjusted for Inflation")

ggplot(sugar_adj, aes(x = month)) +
  geom_line(aes(y = Value, color = "Inflation Rate", group = 1)) +
  geom_line(aes(y = mon_avg, color = "Sugar Price", group = 1)) +
  scale_color_manual(values = c("blue", "red")) +
  xlab("Month") +
  ylab("Value") +
  ggtitle("Inflation Rate and Sugar Prices over Time")



sugar_adj$norm_value <- scale(sugar_adj$Value)
sugar_adj$norm_mon_avg <- scale(sugar_adj$mon_avg)

# Calculate the adjusted sugar price by dividing the monthly average sugar price by the CPI value


# Plot the normalized values for 'Value' and 'mon_avg' and the adjusted sugar price as lines

#changing month to a date
sugar_adj$month <- as.Date(paste0(sugar_adj$month, "-01"))

ggplot(sugar_adj, aes(x = month)) +
  geom_line(aes(y = norm_value, color = "CPI", group = 1)) +
  geom_line(aes(y = norm_mon_avg, color = "Sugar Price", group = 1)) +
  scale_color_manual(values = c("darkblue", "orange")) +
  xlab("Date") +
  ylab("Normalized Values") +
  ggtitle("Inflation Rate vs. Price - Sugar") +
  scale_x_date(date_labels = "%Y")


```

# Arima Sugar
```{r}
##Stationary Test
adf.test(sugar_ts, alternative = "stationary")

## After first-order differencing
adf.test(diff(sugar_ts), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=1

#Custom ARIMA Model

#Correlation Plot and Tuning selection. This plot looks at price correlation with itself in prior time periods. The parameter selection controls for that. 
#ACF (q)
acf(diff(sugar_ts),main='')
#q=2

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(sugar_ts),main='')
#p=2. There are 2 partial auto corelation values

# ARIMA Custom

sugar_fit<- Arima(sugar_ts, order=c(2,1,2))

BIC(sugar_fit)
# Calculate the AICc value

loglik_sugar_fit <- logLik(sugar_fit)

loglik_sugar_fit <- logLik(sugar_fit) - max(loglik_sugar_fit)

n <- length(sugar_ts)
k <- length(coef(sugar_fit))
sugar_fit_AICc <- AIC(sugar_fit) + 2*k*(k+1)/(n-k-1) - 2*loglik_sugar_fit

sugar_fit_AICc

sugar_fit

# ARIMA Alternate Custom

sugar_fit2<- Arima(sugar_ts, order=c(2,1,3))
sugar_fit2

forecast::accuracy(sugar_fit2)

#Check residuals

checkresiduals(sugar_fit2)

#Auto-fit Arima

auto_sugar<- auto.arima(sugar_ts)
auto_sugar

##Forecast Plot

##Forecast Custom

autoplot(forecast::forecast(sugar_fit, h=12, level=c(80,95)))

##Forecast Custom 2

autoplot(forecast::forecast(sugar_fit2, h=12, level=c(80,95)))

##Forecast Auto

autoplot(forecast::forecast(auto_sugar, h=12, level=c(80,95)))


#ARIMA using more recent data

sugar_r2 <- sugar %>%
filter(date >= as.Date('2019-01-01') & date <= as.Date('2023-01-31'))

sugar_r2 <- sugar_r2 %>% group_by(month) %>% mutate(mon_avg = mean(price))%>%
select(month, mon_avg)

#Drop Duplicate rows Sugar

sugar_r2 <- sugar_r2[!duplicated(sugar_r2),]

sugar_tsr <- ts(sugar_r2$mon_avg,start=c(2019),frequency=12)

##Stationary Test
adf.test(sugar_tsr, alternative = "stationary")

## After first-order differencing
adf.test(diff(sugar_tsr), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=2

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(sugar_tsr),main='')
#q=0

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(sugar_tsr),main='')
#p=0. There are 2 partial auto corelation values

# ARIMA Custom

sugar_fitR<- Arima(sugar_tsr, order=c(0,2,0))
sugar_fitR

forecast::accuracy(sugar_fitR)

#Check residuals

checkresiduals(sugar_fitR)

#Auto-fit Arima

auto_sugarR<- auto.arima(sugar_tsr)
auto_sugarR

##Forecast Plot

autoplot(forecast::forecast(auto_sugarR, h=12, level=c(80,95)))

##Forecast Custom

autoplot(forecast::forecast(sugar_fitR, h=12, level=c(80,95)))

#Printing Predictions

sugar_predictions <- forecast::forecast(auto_sugarR,h=12)

print(sugar_predictions$mean)
```
# Sugar GARCH
```{r}

# Model Creation

garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(0,0), include.mean = TRUE), distribution.model = "std")
# Fitting Model to Data

sugar_garch <- ugarchfit(spec = garch_model, data = sugar_ts)

sugar_vol <-ts(sugar_garch@fit$sigma^2,start=c(1993),frequency=12)


print(sugar_garch)

#plot(sugar_garch, which = 1)

coef(sugar_garch)

# Forecasting

horizon <- 3

sugar_forecast_garch <- ugarchforecast(sugar_garch, n.ahead = horizon)

forecast_mean_sugar <- as.numeric(sugar_forecast_garch@forecast$seriesFor)
actual_values_sugar <- as.numeric(window(sugar_vol, start = c(1993, 1)))


plot(sugar_forecast_garch, n.plot = horizon, n.col = 1, plot.type = "single", 
     main = "GARCH Forecast for Sugar Prices", ylab = "Price", xlab = "Time") #%>%
lines(sugar_ts[(length(sugar_ts)-horizon+1):length(sugar_ts)], col = "blue")


#GARCH Take 2
#Use ARIMA values from acf, pacf. Did this in Sugar_fit
sugar_fit
sugar_fit2
sugar_fitR
auto_sugar
auto_sugarR

#Based on significance. Let's try auto_arimas

garch_model2 <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

sugar_garch2 <- ugarchfit(spec = garch_model, data = sugar_ts)
sugar_garch2

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

sugar_vol <-ts(sugar_garch2@fit$sigma^2,start=c(1993),frequency=12)

plot(sugar_vol,xlab="",ylab="",main="Sugar_Volatility (GARCH[1,1])")

#Exponential GARCH (does not work quite as well)
Egarch_model <- ugarchspec(variance.model = list(model = "eGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

sugar_egarch2 <- ugarchfit(spec = garch_model, data = sugar_ts)
sugar_egarch2
coef(sugar_egarch2)

sugar_forecast_garche <- ugarchforecast(sugar_egarch2, n.ahead = horizon)

forecast_mean_sugare <- as.numeric(sugar_forecast_garche@forecast$seriesFor)
actual_values_sugare <- as.numeric(window(sugar_vol, start = c(1993, 1)))

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

esugar_vol <-ts(sugar_egarch2@fit$sigma^2,start=c(1993),frequency=12)

plot(esugar_vol,xlab="",ylab="",main="Sugar_Volatility (eGARCH[1,1])")

cor(sugar_vol, esugar_vol)

ts.plot(sugar_vol,esugar_vol,col=c("green","red"),xlab="")
legend("topright",legend=c("Standard","Exponential"),col=c("green","red"),lty=c(1,1))
#No difference shown

#GARCH 3

names(sugar_garch2@model)
names(sugar_garch2@fit)
#Variance
sugar_garch_var <- sugar_garch2@fit$var
#Residuals
sugar_garch_res <- (sugar_garch2@fit$residuals)^2

#Plotting residuals and conditional variances
plot(sugar_garch_res, type = "l")
lines(sugar_garch_var, col = "green")

sugar_forecast_garch2 <- ugarchforecast(sugar_garch2, n.ahead = 12)
sugar_forecast_garch2

sugar_forecast_values <- as.numeric(sugar_forecast_garch2@forecast$series)
print(sugar_forecast_values)
sugar_forecast_index <- sugar_forecast_garch2@forecast$seriesFor
sugar_forecast <- data.frame(time = sugar_forecast_index, forecast = sugar_forecast_values)
print(sugar_forecast)
#write.csv(sugar_forecast, file="sugar_forecast.csv",row.names = FALSE)

sugar_garch2_fitted <- fitted(sugar_garch2)
#print(sugar_garch2_fitted)


#print(sugar_forecast_values)

#summary(sugar_forecast_garch2)

ug_sugar <- sugar_forecast_garch2@forecast$sigmaFor
#plot(ug_sugar, type = "l")

sug_var_t <- c(tail(sugar_garch_var,20),rep(NA,10))  # gets the last 20 observations
sug_res_t <- c(tail(sugar_garch_res,20),rep(NA,10))  # gets the last 20 observations
sug_f <- c(rep(NA,20),(ug_sugar)^2)

#plot(sug_res_t, type = "l") #Residuals
lines(sug_f, col = "orange") # Predictions 
lines(sug_var_t, col = "green") #Conditional Forecast


#Plot Predictions

sug_mean_forecast <- as.numeric(sugar_forecast_garch2@forecast$seriesFor)

# Get the upper and lower confidence intervals for both 95% and 80%
sug_conf_int_95 <- as.numeric(sugar_forecast_garch2@forecast$upper[, "95%"]) # 95% confidence interval
sug_conf_int_80 <- as.numeric(sugar_forecast_garch2@forecast$upper[, "80%"]) # 80% confidence interval

# Plot the mean forecasted values with the two confidence intervals

#plot(sugar_forecast_garch2, main = "Forecasted coffee Prices (GARCH(1,1))")


```

# Sugar Model Comparison
```{r}

#ARIMA Models
forecast::accuracy(sugar_fit)
forecast::accuracy(sugar_fit2)
forecast::accuracy(auto_sugar)
forecast::accuracy(sugar_fitR)
forecast::accuracy(auto_sugarR)

AIC(sugar_fit2)
BIC(sugar_fit2)

#GARCH Model

actual_values_sugar <- as.numeric(window(sugar_ts))
actual_values_sugar <- head(actual_values_sugar, length(forecast_mean_sugar))

mae <- mean(abs(forecast_mean_sugar - actual_values_sugar))
mse <- mean((forecast_mean_sugar - actual_values_sugar)^2)
rmse <- sqrt(mse)
# Print the results
cat(paste("MAE: ", mae, "\n"))
cat(paste("MSE: ", mse, "\n"))
cat(paste("RMSE: ", rmse, "\n"))

#GARCH Model 2

forecast_mean_sugar2 <- as.numeric(sugar_forecast_garch2@forecast$seriesFor)
actual_values_sugar2 <- as.numeric(window(sugar_ts))
actual_values_sugar2 <- head(actual_values_sugar2, length(forecast_mean_sugar2))


sug_mae <- mean(abs(forecast_mean_sugar2 - actual_values_sugar2))
sug_mse <- mean((forecast_mean_sugar2 - actual_values_sugar2)^2)
sug_rmse <- sqrt(sug_mse)
# Print the results
cat(paste("MAE: ", sug_mae, "\n"))
cat(paste("MSE: ", sug_mse, "\n"))
cat(paste("RMSE: ", sug_rmse, "\n"))


#eGARCH

forecast_mean_sugare <- as.numeric(sugar_forecast_garche@forecast$seriesFor)
actual_values_sugare <- as.numeric(window(sugar_ts))
actual_values_sugare <- head(actual_values_sugar2, length(forecast_mean_sugare))


esug_mae <- mean(abs(forecast_mean_sugare - actual_values_sugare))
esug_mse <- mean((forecast_mean_sugare - actual_values_sugare)^2)
esug_rmse <- sqrt(sug_mse)
# Print the results
cat(paste("MAE: ", esug_mae, "\n"))
cat(paste("MSE: ", esug_mse, "\n"))
cat(paste("RMSE: ", esug_rmse, "\n"))


```


# Exploring Coffee
```{r}
# Looking at the price of Coffee over the last 30 years
ggplot(coffee, aes(date, value)) +
  geom_line() +
  labs(title = "Revenue by Year")
  
#Summary of coffee
summary(coffee)
##Significant changes in price

#Coffee monthly average

coffee_m <- coffee %>% group_by(month) %>% mutate(mon_avg = mean(value))%>%
select(month, mon_avg)

#Drop Duplicate rows

coffee_m <- coffee_m[!duplicated(coffee_m),]

#Creating Time series data

coffee_ts <- ts(coffee_m$mon_avg,start=c(1993),frequency=12)

#Plotting

chartSeries(coffee_ts)
## Significant increases in price in the mid 90's, 2010-2012 and the 2020's

#Looking at trends

autoplot(decompose((coffee_ts)),main="") 

#Coffee looking for daily or weekly trends
coffee_r <- coffee %>%
filter(date >= as.Date('2022-11-01') & date <= as.Date('2023-01-31'))

ggplot(coffee_r, aes(date, value)) +
  geom_line() +
  labs(title = "Coffee Prices Daily") + xlab("time") + ylab("prices")
## No trends by day of week seen

```

# Coffee Arima
```{r}

##Stationary Test
adf.test(coffee_ts, alternative = "stationary")

## After first-order differencing
adf.test(diff(coffee_ts), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(coffee_ts),main='')
#q=4

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(coffee_ts),main='')
#p=4. There are 4 partial auto corelation values

# ARIMA Custom (best fit)

coffee_fit<- Arima(coffee_ts, order=c(4,1,4))
coffee_fit
# ARIMA Alternate Custom

coffee_fit2<- Arima(coffee_ts, order=c(4,1,5))
coffee_fit2

#Check residuals

checkresiduals(coffee_fit)

#Auto-fit Arima

auto_coffee<- auto.arima(coffee_ts)
auto_coffee

##Forecast Plots

##Forecast Custom

autoplot(forecast::forecast(coffee_fit, h=12, level=c(80,95)))

##Forecast Custom 2

autoplot(forecast::forecast(coffee_fit2, h=12, level=c(80,95)))

##Forecast Auto

autoplot(forecast::forecast(auto_coffee, h=12, level=c(80,95)))


#ARIMA using more recent data

coffee_r2 <- coffee %>%
filter(date >= as.Date('2010-01-01') & date <= as.Date('2023-01-31'))

coffee_r2 <- coffee_r2 %>% group_by(month) %>% mutate(mon_avg = mean(value))%>%
select(month, mon_avg)

#Drop Duplicate rows Coffee

coffee_r2 <- coffee_r2[!duplicated(coffee_r2),]

coffee_tsr <- ts(coffee_r2$mon_avg,start=c(2010),frequency=12)

##Stationary Test
adf.test(coffee_tsr, alternative = "stationary")

## After first-order differencing
adf.test(diff(coffee_tsr), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(coffee_tsr),main='')
#q=6

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(coffee_tsr),main='')
#p=2. There are 2 partial auto correlation values

# ARIMA Custom

coffee_fitR<- Arima(coffee_tsr, order=c(2,1,6))
coffee_fitR

#Check residuals

checkresiduals(coffee_fitR)


##Forecast Custom

autoplot(forecast::forecast(coffee_fitR, h=12, level=c(80,95)))


```

# Coffee GARCH
```{r}
# Model Creation
garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(0,0), include.mean = TRUE), distribution.model = "std")
# Fitting Model to Data

coffee_garch <- ugarchfit(spec = garch_model, data = coffee_ts)

coffee_vol <-ts(coffee_garch@fit$sigma^2,start=c(1993),frequency=12)


print(coffee_garch)

plot(coffee_garch, which = 1)

coef(coffee_garch)

# Forecasting

horizon <- 3

coffee_forecast_garch <- ugarchforecast(coffee_garch, n.ahead = horizon)

forecast_mean_coffee <- as.numeric(coffee_forecast_garch@forecast$seriesFor)
actual_values_coffee <- as.numeric(window(coffee_vol, start = c(1993, 1)))


plot(coffee_forecast_garch, n.plot = horizon, n.col = 1, plot.type = "single", 
     main = "GARCH Forecast for coffee Prices", ylab = "Price", xlab = "Time") #%>%
lines(coffee_ts[(length(coffee_ts)-horizon+1):length(coffee_ts)], col = "blue")


#Based on signficance. Let's try auto_arimas

garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

coffee_garch2 <- ugarchfit(spec = garch_model, data = coffee_ts)
coffee_garch2
print(coffee_garch2)

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

coffee_vol <-ts(coffee_garch2@fit$sigma^2,start=c(1993),frequency=12)

plot(coffee_vol,xlab="",ylab="",main="coffee_Volatility (GARCH[1,1])")


#GARCH 3

names(coffee_garch2@model)
names(coffee_garch2@fit)
#Variance
coffee_garch_var <- coffee_garch2@fit$var
#Residuals
coffee_garch_res <- (coffee_garch2@fit$residuals)^2

#Plotting residuals and conditional variances
plot(coffee_garch_res, type = "l")
lines(coffee_garch_var, col = "green")

coffee_forecast_garch2 <- ugarchforecast(coffee_garch2, n.ahead = 12)
coffee_forecast_garch2


ug_coffee <- coffee_forecast_garch2@forecast$sigmaFor
plot(ug_coffee, type = "l")

coffee_var_t <- c(tail(coffee_garch_var,20),rep(NA,10))  # gets the last 20 observations
coffee_res_t <- c(tail(coffee_garch_res,20),rep(NA,10))  # gets the last 20 observations
coffee_f <- c(rep(NA,20),(ug_coffee)^2)

plot(coffee_res_t, type = "l") #Residuals
lines(coffee_f, col = "orange") # Predictions 
lines(coffee_var_t, col = "green") #Conditional Forecast


#Plot Predictions
plot(coffee_forecast_garch2, main = "Forecasted coffee Prices (GARCH(1,1))")
#legend("bottomright", legend = c("Mean", "Lower 95% CI", "Upper 95% CI"), col = c("black", "blue", "red"), lty = 1)

coffee_mean_forecast <- as.numeric(coffee_forecast_garch2@forecast$seriesFor)

# Plot the mean forecasted values with the two confidence intervals

#plot(coffee_forecast_garch2, main = "Forecasted coffee Prices (GARCH(1,1))")

```

# Coffee Model Comparison
```{r}
#ARIMA Models
forecast::accuracy(coffee_fit)
forecast::accuracy(coffee_fit2)
forecast::accuracy(auto_coffee)
forecast::accuracy(coffee_fitR)

AIC(coffee_fit)
BIC(coffee_fit)

AIC(coffee_fit2)
BIC(coffee_fit2)

AIC(coffee_fitR)
BIC(coffee_fitR)


#GARCH Model

actual_values_coffee <- as.numeric(window(coffee_ts))
actual_values_coffee <- head(actual_values_coffee, length(forecast_mean_coffee))

mae <- mean(abs(forecast_mean_coffee - actual_values_coffee))
mse <- mean((forecast_mean_coffee - actual_values_coffee)^2)
rmse <- sqrt(mse)

# Print the results
cat(paste("MAE: ", mae, "\n"))
cat(paste("MSE: ", mse, "\n"))
cat(paste("RMSE: ", rmse, "\n"))


#GARCH Model 2

forecast_mean_coffee2 <- as.numeric(coffee_forecast_garch2@forecast$seriesFor)
actual_values_coffee2 <- as.numeric(window(coffee_ts))
actual_values_coffee2 <- head(actual_values_coffee2, length(forecast_mean_coffee2))


coffee_mae <- mean(abs(forecast_mean_coffee2 - actual_values_coffee2))
coffee_mse <- mean((forecast_mean_coffee2 - actual_values_coffee2)^2)
coffee_rmse <- sqrt(coffee_mse)
# Print the results
cat(paste("MAE: ", coffee_mae, "\n"))
cat(paste("MSE: ", coffee_mse, "\n"))
cat(paste("RMSE: ", coffee_rmse, "\n"))

```

# Exploring Aluminum
```{r}
#Looking at the price of Aluminum over the last 30 years
ggplot(Aluminum, aes(date, Price)) +
  geom_line() +
  labs(title = "Revenue by Day")
  
#Summary Aluminum
summary(Aluminum)
## Low price is less than half of highest cost.
  
#Aluminum monthly average

alum_m <- Aluminum %>% group_by(month) %>% mutate(mon_avg = mean(Price))%>%
select(month, mon_avg)

#Drop Duplicate rows Aluminum

alum_m <- alum_m[!duplicated(alum_m),]

#Creating Time series data Aluminum

alum_ts <- ts(alum_m$mon_avg,start=c(2002),frequency=12)

#Plotting Aluminum

chartSeries(alum_ts)
#Huge spike in price in early 2000's unique among commodities

#Looking at trends
autoplot(decompose((alum_ts)),main="") 


#Looking for daily or weekly trends Aluminum
Aluminum_r <- Aluminum %>%
filter(date >= as.Date('2022-12-31') & date <= as.Date('2023-01-31'))

ggplot(Aluminum_r, aes(date, Price)) +
  geom_line() +
  labs(title = "Aluminum Prices Daily") + xlab("time") + ylab("prices")
## No weekly trends shown through plotting


#Aluminum Prices Controlling for inflation


alum_CPI <- read.csv("alum_cpi.csv")

alum_adj <- left_join(alum_m, alum_CPI, by = c("month" = "date"))

alum_adj$adj_price <- alum_adj$mon_avg / alum_adj$Value

alum_ts_adj <- ts(alum_adj$adj_price, start = c(2003), frequency = 12)


 chartSeries(alum_ts)

ggplot(data = alum_adj, aes(x = month, y = adj_price, group = 1)) +
  geom_line() +
  labs(x = "Month", y = "Adjusted alum Price", title = "alum Prices Adjusted for Inflation")


#Inflation vs. Price without scaling
ggplot(alum_adj, aes(x = month)) +
  geom_line(aes(y = Value, color = "Inflation Rate", group = 1)) +
  geom_line(aes(y = mon_avg, color = "alum Price", group = 1)) +
  scale_color_manual(values = c("blue", "red")) +
  xlab("Month") +
  ylab("Value") +
  ggtitle("Inflation Rate and alum Prices over Time")


# Scaling the data
alum_adj$norm_value <- scale(alum_adj$Value)
alum_adj$norm_mon_avg <- scale(alum_adj$mon_avg)

# Calculate the adjusted alum price by dividing the monthly average alum price by the CPI value


# Plot the normalized values for 'Value' and 'mon_avg' and the adjusted alum price as lines

alum_adj$month <- as.Date(paste0(alum_adj$month, "-01"))

ggplot(alum_adj, aes(x = month)) +
  geom_line(aes(y = norm_value, color = "CPI", group = 1)) +
  geom_line(aes(y = norm_mon_avg, color = "alum Price", group = 1)) +
  scale_color_manual(values = c("darkblue", "orange")) +
  xlab("Date") +
  ylab("Normalized Values") +
  ggtitle("Inflation Rate vs. Price - Aluminum") +
  scale_x_date(date_labels = "%Y")


```

# Aluminum ARIMA
```{r}
##Stationary Test
adf.test(alum_ts, alternative = "stationary")

## After first-order differencing
adf.test(diff(alum_ts), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(alum_ts),main='')
#q=3

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(alum_ts),main='')
#p=3. There are 3 partial auto correlation values

# ARIMA Custom (best fit)

aluminum_fit<- Arima(alum_ts, order=c(3,1,3))
aluminum_fit
# ARIMA Alternate Custom

aluminum_fit2<- Arima(alum_ts, order=c(3,1,2))
aluminum_fit2

#Check residuals

checkresiduals(aluminum_fit)

#Auto-fit Arima

auto_aluminum<- auto.arima(alum_ts)
auto_aluminum

##Forecast Plots

##Forecast Custom

autoplot(forecast::forecast(aluminum_fit, h=12, level=c(80,95)))

##Forecast Custom 2

autoplot(forecast::forecast(aluminum_fit2, h=12, level=c(80,95)))

##Forecast Auto

autoplot(forecast::forecast(auto_aluminum, h=12, level=c(80,95)))


#ARIMA using more recent data

aluminum_r2 <- Aluminum %>%
filter(date >= as.Date('2019-01-01') & date <= as.Date('2023-01-31'))

aluminum_r2 <- aluminum_r2 %>% group_by(month) %>% mutate(mon_avg = mean(Price))%>%
select(month, mon_avg)

#Drop Duplicate rows Aluminum

aluminum_r2 <- aluminum_r2[!duplicated(aluminum_r2),]

alum_tsr <- ts(aluminum_r2$mon_avg,start=c(2019),frequency=12)

##Stationary Test
adf.test(alum_tsr, alternative = "stationary")

## After first-order differencing
adf.test(diff(alum_tsr), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(alum_tsr),main='')
#q=1

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(alum_tsr),main='')
#p=2. There are 2 partial auto correlation values

# ARIMA Custom

aluminum_fitR<- Arima(alum_tsr, order=c(2,1,1))
aluminum_fitR

#Check residuals

checkresiduals(aluminum_fitR)

##Forecast Custom

autoplot(forecast::forecast(aluminum_fitR, h=12, level=c(80,95)))

#Printing Predictions

aluminum_predictions <- forecast::forecast(aluminum_fitR,h=12)

print(aluminum_predictions$mean)

```


# Aluminum GARCH
```{r}
# Model Creation
garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(0,0), include.mean = TRUE), distribution.model = "std")
# Fitting Model to Data



alum_fit <- ugarchfit(spec = garch_model, data = alum_ts)

print(alum_fit)

#plot(alum_fit, which = 1)

coef(alum_fit)

# Forecasting

horizon <- 3

alum_forecast_garch <- ugarchforecast(alum_fit, n.ahead = horizon)

forecast_mean_alum <- as.numeric(alum_forecast_garch@forecast$seriesFor)
actual_values_alum <- as.numeric(window(alum_ts, start = c(1993, 1)))


plot(alum_forecast_garch, n.plot = horizon, n.col = 1, plot.type = "single", 
     main = "GARCH Forecast for alum Prices", ylab = "Price", xlab = "Time") #%>%
lines(alum_ts[(length(alum_ts)-horizon+1):length(alum_ts)], col = "blue")


#Based on signficance. Let's try auto_arimas

garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

alum_garch2 <- ugarchfit(spec = garch_model, data = alum_ts)
alum_garch2

alum_vol <-ts(alum_garch2@fit$sigma^2,start=c(1993),frequency=12)

print(alum_garch2)

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

alum_vol <-ts(alum_garch2@fit$sigma^2,start=c(1993),frequency=12)

#plot(alum_vol,xlab="",ylab="",main="alum_Volatility (GARCH[1,1])")


#GARCH 3

names(alum_garch2@model)
names(alum_garch2@fit)
#Variance
alum_garch_var <- alum_garch2@fit$var
#Residuals
alum_garch_res <- (alum_garch2@fit$residuals)^2

#Plotting residuals and conditional variances
plot(alum_garch_res, type = "l")
lines(alum_garch_var, col = "green")

alum_forecast_garch2 <- ugarchforecast(alum_garch2, n.ahead = 12)
alum_forecast_garch2

ug_alum <- alum_forecast_garch2@forecast$sigmaFor
plot(ug_alum, type = "l")

alum_var_t <- c(tail(alum_garch_var,20),rep(NA,10))  # gets the last 20 observations
alum_res_t <- c(tail(alum_garch_res,20),rep(NA,10))  # gets the last 20 observations
alum_f <- c(rep(NA,20),(ug_alum)^2)

plot(alum_res_t, type = "l") #Residuals
lines(alum_f, col = "orange") # Predictions 
lines(alum_var_t, col = "green") #Conditional Forecast


#Plot Predictions
plot(alum_forecast_garch2, main = "Forecasted alum Prices (GARCH(1,1))")
legend("bottomright", legend = c("Mean", "Lower 95% CI", "Upper 95% CI"), col = c("black", "blue", "red"), lty = 1)

alum_mean_forecast <- as.numeric(alum_forecast_garch2@forecast$seriesFor)


```

# Model Comparison Alum
```{r}
#ARIMA Models
forecast::accuracy(aluminum_fit)
forecast::accuracy(aluminum_fit2)
forecast::accuracy(auto_aluminum)
forecast::accuracy(aluminum_fitR)

AIC(aluminum_fit)
BIC(aluminum_fit)

AIC(aluminum_fit2)
BIC(aluminum_fit2)

AIC(aluminum_fitR)
BIC(aluminum_fitR)

#GARCH Model

actual_values_alum <- head(actual_values_alum, length(forecast_mean_alum))

mae <- mean(abs(forecast_mean_alum - actual_values_alum))
mse <- mean((forecast_mean_alum - actual_values_alum)^2)
rmse <- sqrt(mse)

# Print the results
cat(paste("MAE: ", mae, "\n"))
cat(paste("MSE: ", mse, "\n"))
cat(paste("RMSE: ", rmse, "\n"))

#GARCH Model 2

forecast_mean_alum2 <- as.numeric(alum_forecast_garch2@forecast$seriesFor)
actual_values_alum2 <- as.numeric(window(alum_ts, start = c(1993, 1)))
actual_values_alum2 <- head(actual_values_alum2, length(forecast_mean_alum2))


alum_mae <- mean(abs(forecast_mean_alum2 - actual_values_alum2))
alum_mse <- mean((forecast_mean_alum2 - actual_values_alum2)^2)
alum_rmse <- sqrt(alum_mse)
# Print the results
cat(paste("MAE: ", alum_mae, "\n"))
cat(paste("MSE: ", alum_mse, "\n"))
cat(paste("RMSE: ", alum_rmse, "\n"))


```


# Exploring Soybean
```{r}

# Looking at the price of Soybean over the last 30 years
ggplot(soybean, aes(date, value)) +
  geom_line() +
  labs(title = "Revenue by Day")
  
#Summary
summary(soybean)
## Price has increased significantly over 30 years, outpacing inflation.

#Soybean monthly average

soy_m <- soybean %>% group_by(month) %>% mutate(mon_avg = mean(value))%>%
select(month, mon_avg)

#Drop Duplicate rows Soybean

soy_m <- soy_m[!duplicated(soy_m),]

#Creating Time series data Soybean

soy_ts <- ts(soy_m$mon_avg,start=c(1993),frequency=12)

#Plotting Soybean

chartSeries(soy_ts)
## Price jumps in 2008, 2010 and 2020's.

#Looking at trends

autoplot(decompose((soy_ts)),main="") 

#Looking for daily or weekly trends Soybean
soybean_r <- soybean %>%
filter(date >= as.Date('2022-11-01') & date <= as.Date('2022-12-01'))

ggplot(soybean_r, aes(date, value)) +
  geom_line() +
  labs(title = "Soybean Prices Daily") + xlab("time") + ylab("prices")
## No daily trends detected

```


# Soybean ARIMA
```{r}
##Stationary Test
adf.test(soy_ts, alternative = "stationary")

## After first-order differencing
adf.test(diff(soy_ts), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(soy_ts),main='')
#q=5

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(soy_ts),main='')
#p=3. There are 3 partial auto correlation values

# ARIMA Custom(best fit)

soy_fit<- Arima(soy_ts, order=c(3,1,5))
soy_fit

#Check residuals

checkresiduals(soy_fit)

#Auto-fit Arima

auto_soy<- auto.arima(soy_ts)
auto_soy

##Forecast Plots

##Forecast Custom

autoplot(forecast::forecast(soy_fit, h=12, level=c(80,95)))

##Forecast Auto (overfit)

autoplot(forecast::forecast(auto_soy, h=12, level=c(80,95)))


#ARIMA using more recent data

soy_r2 <- soybean %>%
filter(date >= as.Date('2019-01-01') & date <= as.Date('2023-01-31'))

soy_r2 <- soy_r2 %>% group_by(month) %>% mutate(mon_avg = mean(value))%>%
select(month, mon_avg)

#Drop Duplicate rows soy

soy_r2 <- soy_r2[!duplicated(soy_r2),]

soy_tsr <- ts(soy_r2$mon_avg,start=c(2019),frequency=12)

##Stationary Test
adf.test(soy_tsr, alternative = "stationary")
#Low p-value already

## After first-order differencing
adf.test(diff(soy_tsr), alternative ="stationary")
#This decreases our p-value and creates significance
#d=0

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(soy_tsr),main='')
#q=6

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(soy_tsr),main='')
#p=1. There are 2 partial auto correlation values

# ARIMA Custom(better model)

soy_fitR<- Arima(soy_tsr, order=c(1,0,6))
soy_fitR

#Check residuals

checkresiduals(soy_fitR)


##Forecast Custom

autoplot(forecast::forecast(soy_fitR, h=12, level=c(80,95)))

#Printing Predictions

soy_predictions <- forecast::forecast(soy_fitR,h=12)

print(soy_predictions$mean)

print(soy_predictions$mean)


```


# Soy Garch
```{r}
# Model Creation
garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(0,0), include.mean = TRUE), distribution.model = "std")
# Fitting Model to Data

soy_garch <- ugarchfit(spec = garch_model, data = soy_ts)

print(soy_garch)

#plot(soy_garch, which = 1)

coef(soy_garch)

# Forecasting

horizon <- 3

soy_forecast_garch <- ugarchforecast(soy_garch, n.ahead = horizon)

forecast_mean_soy <- as.numeric(soy_forecast_garch@forecast$seriesFor)
actual_values_soy <- as.numeric(window(soy_ts, start = c(1993, 1)))


plot(soy_forecast_garch, n.plot = horizon, n.col = 1, plot.type = "single", 
     main = "GARCH Forecast for soy Prices", ylab = "Price", xlab = "Time") #%>%
lines(soy_ts[(length(soy_ts)-horizon+1):length(soy_ts)], col = "blue")


#Based on signficance. Let's try auto_arimas

garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

soy_garch2 <- ugarchfit(spec = garch_model, data = soy_ts)
soy_garch2
print(soy_garch2)

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

soy_vol <-ts(soy_garch2@fit$sigma^2,start=c(1993),frequency=12)

#plot(soy_vol,xlab="",ylab="",main="soy_Volatility (GARCH[1,1])")


#GARCH 3

names(soy_garch2@model)
names(soy_garch2@fit)
#Variance
soy_garch_var <- soy_garch2@fit$var
#Residuals
soy_garch_res <- (soy_garch2@fit$residuals)^2

#Plotting residuals and conditional variances
plot(soy_garch_res, type = "l")
lines(soy_garch_var, col = "green")

soy_forecast_garch2 <- ugarchforecast(soy_garch2, n.ahead = 12)
soy_forecast_garch2

ug_soy <- soy_forecast_garch2@forecast$sigmaFor
#plot(ug_soy, type = "l")

soy_var_t <- c(tail(soy_garch_var,20),rep(NA,10))  # gets the last 20 observations
soy_res_t <- c(tail(soy_garch_res,20),rep(NA,10))  # gets the last 20 observations
soy_f <- c(rep(NA,20),(ug_soy)^2)

plot(soy_res_t, type = "l") #Residuals
lines(soy_f, col = "orange") # Predictions 
lines(soy_var_t, col = "green") #Conditional Forecast
legend("topright", 
       legend = c("Residuals", "Predictions", "Conditional Forecast"), 
       col = c("black", "orange", "green"), 
       lty = c(1, 1, 1), 
       cex = 0.8)

#Plot Predictions
plot(soy_forecast_garch2, main = "Forecasted soy Prices (GARCH(1,1))")
#legend("bottomright", legend = c("Mean", "Lower 95% CI", "Upper 95% CI"), col = c("black", "blue", "red"), lty = 1)

soy_mean_forecast <- as.numeric(soy_forecast_garch2@forecast$seriesFor)


# Plot the mean forecasted values with the two confidence intervals

#plot(soy_forecast_garch2, main = "Forecasted soy Prices (GARCH(1,1))")




```


# Soybean Model Comparison
```{r}
#ARIMA Models
forecast::accuracy(soy_fit)
forecast::accuracy(auto_soy)
forecast::accuracy(soy_fitR)

AIC(soy_fit)
BIC(soy_fit)

AIC(soy_fitR)
BIC(soy_fitR)


#GARCH Model

actual_values_soy <- head(actual_values_soy, length(forecast_mean_soy))

mae <- mean(abs(forecast_mean_soy - actual_values_soy))
mse <- mean((forecast_mean_soy - actual_values_soy)^2)
rmse <- sqrt(mse)

# Print the results
cat(paste("MAE: ", mae, "\n"))
cat(paste("MSE: ", mse, "\n"))
cat(paste("RMSE: ", rmse, "\n"))


#GARCH Model 2

forecast_mean_soy2 <- as.numeric(soy_forecast_garch2@forecast$seriesFor)
actual_values_soy2 <- as.numeric(window(soy_ts, start = c(1993, 1)))
actual_values_soy2 <- head(actual_values_soy2, length(forecast_mean_soy2))

soy_mae <- mean(abs(forecast_mean_soy2 - actual_values_soy2))
soy_mse <- mean((forecast_mean_soy2 - actual_values_soy2)^2)
soy_rmse <- sqrt(soy_mse)
# Print the results
cat(paste("MAE: ", soy_mae, "\n"))
cat(paste("MSE: ", soy_mse, "\n"))
cat(paste("RMSE: ", soy_rmse, "\n"))


```


# Exploring Soybean Oil
```{r Soybean Oil}
# Looking at the price of Soybean Oil over the last 30 years
ggplot(soybeanoil, aes(date, price)) +
  geom_line() +
  labs(title = "Revenue by Day")
  
#Summary
summary(soybeanoil)
## All time high price in June of 2022
  
#Soybeanoil monthly average

soyo_m <- soybeanoil %>% group_by(month) %>% mutate(mon_avg = mean(price))%>%
select(month, mon_avg)

#Drop Duplicate rows Soybean Oil

soyo_m <- soyo_m[!duplicated(soyo_m),]

#Creating Time series data Soybean oil

soyo_ts <- ts(soyo_m$mon_avg,start=c(1993),frequency=12)

#Plotting Soybean Oil

chartSeries(soyo_ts)
## Price hikes in 2008, 2012 and 2020's

#Looking at trends
autoplot(decompose((soyo_ts)),main="") 

#Looking for daily or weekly trends Soybean oil
soyo_r <- soybeanoil %>%
filter(date >= as.Date('2022-04-01') & date <= as.Date('2023-06-01'))

ggplot(soyo_r, aes(date, price)) +
  geom_line() +
  labs(title = "Soybean Oil Prices Daily") + xlab("time") + ylab("prices")
# No price trends by day seen

```


# Soybean oil ARIMA models
```{r}
##Stationary Test
adf.test(soyo_ts, alternative = "stationary")

## After first-order differencing
adf.test(diff(soyo_ts), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(soyo_ts),main='')
#q=4

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(soyo_ts),main='')
#p=3. There are 3 partial auto correlation values

# ARIMA Custom(best fit)

soyo_fit<- Arima(soyo_ts, order=c(3,1,4))
soyo_fit

#Check residuals

checkresiduals(soyo_fit)

#Auto-fit Arima

auto_soyo<- auto.arima(soyo_ts)
auto_soyo

##Forecast Plots

##Forecast Custom(better model)

autoplot(forecast::forecast(soyo_fit, h=12, level=c(80,95)))

##Forecast Auto (overfit)

autoplot(forecast::forecast(auto_soyo, h=12, level=c(80,95)))


#ARIMA using more recent data

soyo_r2 <- soybeanoil %>%
filter(date >= as.Date('2016-01-01') & date <= as.Date('2023-01-31'))

soyo_r2 <- soyo_r2 %>% group_by(month) %>% mutate(mon_avg = mean(price))%>%
select(month, mon_avg)

#Drop Duplicate rows

soyo_r2 <- soyo_r2[!duplicated(soyo_r2),]

soyo_tsr <- ts(soyo_r2$mon_avg,start=c(2016),frequency=12)

##Stationary Test
adf.test(soyo_tsr, alternative = "stationary")


## After first-order differencing
adf.test(diff(soyo_tsr), alternative ="stationary")
#This decreases our p-value and creates significance
#d=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(soyo_tsr),main='')
#q=1

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(soyo_tsr),main='')
#p=1. There are 2 partial auto correlation values

# ARIMA Custom(better model)

soyo_fitR<- Arima(soyo_tsr, order=c(1,1,1))
soyo_fitR

#Check residuals

checkresiduals(soyo_fitR)


##Forecast Custom

autoplot(forecast::forecast(soyo_fitR, h=12, level=c(80,95)))

#Printing Predictions

soyo_predictions <- forecast::forecast(soyo_fitR,h=12)

print(soyo_predictions$mean)


print(soyo_predictions$mean)

```


# GARCH Soybean Oil Modeling
```{r}
# Model Creation
garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(0,0), include.mean = TRUE), distribution.model = "std")
# Fitting Model to Data

soyo_garch <- ugarchfit(spec = garch_model, data = soyo_ts)

print(soyo_garch)

#plot(soyo_garch, which = 1)

coef(soyo_garch)

# Forecasting

horizon <- 3

soyo_vol <-ts(soyo_garch@fit$sigma^2,start=c(1993),frequency=12)

soyo_forecast_garch <- ugarchforecast(soyo_garch, n.ahead = 12)

forecast_mean_soyo <- as.numeric(soyo_forecast_garch@forecast$seriesFor)
actual_values_soyo <- as.numeric(window(soyo_ts, start = c(1993, 1)))


plot(soyo_forecast_garch, n.plot = horizon, n.col = 1, plot.type = "single", 
     main = "GARCH Forecast for soyo Prices", ylab = "Price", xlab = "Time") #%>%
lines(soyo_ts[(length(soyo_ts)-horizon+1):length(soyo_ts)], col = "blue")


#Based on signficance. Let's try auto_arimas

garch_model2 <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

soyo_garch2 <- ugarchfit(spec = garch_model2, data = soyo_ts)
soyo_garch2

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

#soyo_vol2 <-ts(soyo_garch2@fit$sigma^2,start=c(1993),frequency=12)

#plot(soyo_vol2,xlab="",ylab="",main="soyo_Volatility (GARCH[1,1])")



#GARCH 3

names(soyo_garch2@model)
names(soyo_garch2@fit)
#Variance
soyo_garch_var <- soyo_garch2@fit$var
#Residuals
soyo_garch_res <- (soyo_garch2@fit$residuals)^2

#Plotting residuals and conditional variances
#plot(soyo_garch_res, type = "l")
#lines(soyo_garch_var, col = "green")

#soyo_forecast_garch2 <- ugarchforecast(soyo_garch2, n.ahead = 12)
#soyo_forecast_garch2


```

# soyobean Oil Model Comparison
```{r}
#ARIMA Models
forecast::accuracy(soyo_fit)
forecast::accuracy(auto_soyo)
forecast::accuracy(soyo_fitR)

AIC(soyo_fit)
BIC(soyo_fit)

AIC(soyo_fitR)
BIC(soyo_fitR)

#GARCH Model

actual_values_soyo <- head(actual_values_soyo, length(forecast_mean_soyo))

mae <- mean(abs(forecast_mean_soyo - actual_values_soyo))
mse <- mean((forecast_mean_soyo - actual_values_soyo)^2)
rmse <- sqrt(mse)

# Print the results
cat(paste("MAE: ", mae, "\n"))
cat(paste("MSE: ", mse, "\n"))
cat(paste("RMSE: ", rmse, "\n"))

```

# Exploring Corn
```{r Corn}
# Looking at the price of Corn over the last 30 years
ggplot(corn, aes(date, price)) +
  geom_line() +
  labs(title = "Revenue by Day")
  
#Summary Corn
summary(corn)
## Corn price reached an all time high in February of 2023
  
#Corn monthly average

corn_m <- corn %>% group_by(month) %>% mutate(mon_avg = mean(price))%>%
select(month, mon_avg)

#Drop Duplicate rows Corn

corn_m <- corn_m[!duplicated(corn_m),]

#Creating Time series data Corn

corn_ts <- ts(corn_m$mon_avg,start=c(1993),frequency=12)

#Plotting Corn

chartSeries(corn_ts)
## Price hikes in 1995, 2008, 2010's and 2020's

#Looking at trends

autoplot(decompose((corn_ts)),main="") 

#Looking for daily or weekly trends Corn
corn_r <- corn %>%
filter(date >= as.Date('2022-11-01') & date <= as.Date('2023-01-31'))

ggplot(corn_r, aes(date, price)) +
  geom_line() +
  labs(title = "Corn Prices Daily") + xlab("time") + ylab("prices")
## Price does not seem to fluctuate by day of the week

```


# Corn ARIMA models
```{r}
##Stationary Test
adf.test(corn_ts, alternative = "stationary")

## After first-order differencing
adf.test(diff(corn_ts), alternative ="stationary")
#This decreases our p-value and creates significance
#Data is now stationary making the value of (d)=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(corn_ts),main='')
#q=4

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(corn_ts),main='')
#p=4. There are 4 partial auto correlation values

# ARIMA Custom(best fit)

corn_fit<- Arima(corn_ts, order=c(4,1,4))
corn_fit

#Check residuals

checkresiduals(corn_fit)

#Auto-fit Arima

auto_corn<- auto.arima(corn_ts)
auto_corn
checkresiduals(auto_corn)
##Forecast Plots

##Forecast Custom(better model)

autoplot(forecast::forecast(corn_fit, h=12, level=c(80,95)))

##Forecast Auto (overfit)

autoplot(forecast::forecast(auto_corn, h=12, level=c(80,95)))


#ARIMA using more recent data

corn_r2 <- corn %>%
filter(date >= as.Date('2016-01-01') & date <= as.Date('2023-01-31'))

corn_r2 <- corn_r2 %>% group_by(month) %>% mutate(mon_avg = mean(price))%>%
select(month, mon_avg)

#Drop Duplicate rows

corn_r2 <- corn_r2[!duplicated(corn_r2),]

corn_tsr <- ts(corn_r2$mon_avg,start=c(2016),frequency=12)

##Stationary Test
adf.test(corn_tsr, alternative = "stationary")


## After first-order differencing
adf.test(diff(corn_tsr), alternative ="stationary")
#This decreases our p-value and creates significance
#d=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(corn_tsr),main='')
#q=1

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(corn_tsr),main='')
#p=3. There are 3 partial auto correlation values

# ARIMA Custom(overfit)

corn_fitR<- Arima(corn_tsr, order=c(3,1,1))
corn_fitR

#Check residuals

checkresiduals(corn_fitR)

#Auto-fit Arima(overfit)

auto_cornR<- auto.arima(corn_tsr)
auto_cornR
checkresiduals(auto_cornR)

##Forecast Plot

autoplot(forecast::forecast(auto_cornR, h=12, level=c(80,95)))

##Forecast Custom

autoplot(forecast::forecast(corn_fitR, h=12, level=c(80,95)))

#Printing Predictions

corn_predictions <- forecast::forecast(corn_fitR,h=12)

print(corn_predictions$mean)

corn_predictions <- forecast::forecast(auto_cornR,h=12)

print(corn_predictions$mean)
```


# GARCH Corn Modeling
```{r}
# Model Creation
garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(0,0), include.mean = TRUE), distribution.model = "std")
# Fitting Model to Data

corn_garch <- ugarchfit(spec = garch_model, data = corn_ts)

print(corn_garch)

#plot(corn_garch, which = 1)

coef(corn_garch)

# Forecasting

horizon <- 3

corn_forecast_garch <- ugarchforecast(corn_garch, n.ahead = horizon)

corn_forecast_mean <- as.numeric(corn_forecast_garch@forecast$seriesFor)
corn_actual_values <- as.numeric(window(corn_ts, start = c(1993, 1)))


#plot(corn_forecast_garch, n.plot = horizon, n.col = 1, plot.type = "single", 
    # main = "GARCH Forecast for corn Prices", ylab = "Price", xlab = "Time") #%>%
#lines(corn_ts[(length(corn_ts)-horizon+1):length(corn_ts)], col = "blue")



#Based on signficance. Let's try auto_arimas

garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

corn_garch2 <- ugarchfit(spec = garch_model, data = corn_ts)
corn_garch2

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

corn_vol <-ts(corn_garch2@fit$sigma^2,start=c(1993),frequency=12)

plot(corn_vol,xlab="",ylab="",main="corn_Volatility (GARCH[1,1])")

#Exponential GARCH
Egarch_model <- ugarchspec(variance.model = list(model = "eGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

corn_egarch2 <- ugarchfit(spec = garch_model, data = corn_ts)
corn_egarch2
coef(corn_egarch2)

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

ecorn_vol <-ts(corn_egarch2@fit$sigma^2,start=c(1993),frequency=12)

#plot(ecorn_vol,xlab="",ylab="",main="corn_Volatility (eGARCH[1,1])")

cor(corn_vol, ecorn_vol)

#ts.plot(corn_vol,ecorn_vol,col=c("green","red"),xlab="")
#legend("topright",legend=c("Standard","Exponential"),col=c("green","red"),lty=c(1,1))
#No difference shown

#GARCH 3

names(corn_garch2@model)
names(corn_garch2@fit)
#Variance
corn_garch_var <- corn_garch2@fit$var
#Residuals
corn_garch_res <- (corn_garch2@fit$residuals)^2

#Plotting residuals and conditional variances
plot(corn_garch_res, type = "l")
lines(corn_garch_var, col = "green")

corn_forecast_garch2 <- ugarchforecast(corn_garch2, n.ahead = 12)
corn_forecast_garch2

ug_corn <- corn_forecast_garch2@forecast$sigmaFor
plot(ug_corn, type = "l")

corn_var_t <- c(tail(corn_garch_var,20),rep(NA,10))  # gets the last 20 observations
corn_res_t <- c(tail(corn_garch_res,20),rep(NA,10))  # gets the last 20 observations
corn_f <- c(rep(NA,20),(ug_corn)^2)

plot(corn_res_t, type = "l") #Residuals
lines(corn_f, col = "orange") # Predictions 
lines(corn_var_t, col = "green") #Conditional Forecast
legend("topright", 
       legend = c("Residuals", "Predictions", "Conditional Forecast"), 
       col = c("black", "orange", "green"), 
       lty = c(1, 1, 1), 
       cex = 0.8)

#Plot Predictions
#plot(corn_forecast_garch2, main = "Forecasted corn Prices (GARCH(1,1))")
#legend("bottomright", legend = c("Mean", "Lower 95% CI", "Upper 95% CI"), col = c("black", "blue", "red"), lty = 1)

corn_mean_forecast <- as.numeric(corn_forecast_garch2@forecast$seriesFor)


```


# Corn Model Comparison
```{r}
#ARIMA Models
forecast::accuracy(corn_fit)
forecast::accuracy(auto_corn)
forecast::accuracy(corn_fitR)
forecast::accuracy(auto_cornR)

AIC(corn_fit)
BIC(corn_fit)

AIC(corn_fitR)
BIC(corn_fitR)


#GARCH Model

corn_actual_values <- head(corn_actual_values, length(corn_forecast_mean))

mae <- mean(abs(corn_mean_forecast - corn_actual_values))
mse <- mean((corn_mean_forecast - corn_actual_values)^2)
rmse <- sqrt(mse)

# Print the results
cat(paste("MAE: ", mae, "\n"))
cat(paste("MSE: ", mse, "\n"))
cat(paste("RMSE: ", rmse, "\n"))

forecast_mean_corn2 <- as.numeric(corn_forecast_garch2@forecast$seriesFor)
actual_values_corn2 <- as.numeric(window(corn_ts, start = c(1993, 1)))
actual_values_corn2 <- head(actual_values_corn2, length(forecast_mean_corn2))

corn_mae <- mean(abs(forecast_mean_corn2 - actual_values_corn2))
corn_mse <- mean((forecast_mean_corn2 - actual_values_corn2)^2)
corn_rmse <- sqrt(corn_mse)
# Print the results
cat(paste("MAE: ", corn_mae, "\n"))
cat(paste("MSE: ", corn_mse, "\n"))
cat(paste("RMSE: ", corn_rmse, "\n"))

corn_garch
corn_garch2

```


# Exploring Cotton
```{r Cotton}
# Looking at the price of Cotton over the last 30 years
ggplot(cotton, aes(date, price)) +
  geom_line() +
  labs(title = "Revenue by Day")
  
#Summary of Cotton
summary(cotton)
  
#Cotton monthly average

cotton_m <- cotton %>% group_by(month) %>% mutate(mon_avg = mean(price))%>%
select(month, mon_avg)

#Drop Duplicate rows Cotton

cotton_m <- cotton_m[!duplicated(cotton_m),]

#Creating Time series data Cotton

cotton_ts <- ts(cotton_m$mon_avg,start=c(1993),frequency=12)

#Plotting Cotton

chartSeries(cotton_ts)
## Huge price hike in 2012

#Looking at trends
autoplot(decompose((cotton_ts)),main="") 


#Looking for daily or weekly trends Cotton
cotton_r <- cotton %>%
filter(date >= as.Date('2022-1-01') & date <= as.Date('2022-12-31'))

ggplot(cotton_r, aes(date, price)) +
  geom_line() +
  labs(title = "Cotton Prices Daily") + xlab("time") + ylab("prices")
## Price does not seem to fluctuate by day of the week

```

# Cotton ARIMA models
```{r}
##Stationary Test
adf.test(cotton_ts, alternative = "stationary")

## After first-order differencing
adf.test(diff(cotton_ts), alternative ="stationary")
#This decreases our p-value and creates significance
#Already a low p value d = 0

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(cotton_ts),main='')
#q=6

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(cotton_ts),main='')
#p=4. There are 4 partial auto correlation values

# ARIMA Custom(best fit)

cotton_fit<- Arima(cotton_ts, order=c(4,0,6))
cotton_fit

#Check residuals

checkresiduals(cotton_fit)

#Auto-fit Arima

auto_cotton<- auto.arima(cotton_ts)
auto_cotton
checkresiduals(auto_cotton)
##Forecast Plots

##Forecast Custom

autoplot(forecast::forecast(cotton_fit, h=12, level=c(80,95))) #(better model)

##Forecast Auto 

autoplot(forecast::forecast(auto_cotton, h=12, level=c(80,95)))#(overfit)


#ARIMA using more recent data

cotton_r2 <- cotton %>%
filter(date >= as.Date('2016-01-01') & date <= as.Date('2023-01-31'))

cotton_r2 <- cotton_r2 %>% group_by(month) %>% mutate(mon_avg = mean(price))%>%
select(month, mon_avg)

#Drop Duplicate rows

cotton_r2 <- cotton_r2[!duplicated(cotton_r2),]

cotton_tsr <- ts(cotton_r2$mon_avg,start=c(2016),frequency=12)

##Stationary Test
adf.test(cotton_tsr, alternative = "stationary")


## After first-order differencing
adf.test(diff(cotton_tsr), alternative ="stationary")
#This decreases our p-value and creates significance
#d=1

#Custom Arima Model

#Correlation Plot and Tuning selection
#ACF (q)
acf(diff(cotton_tsr),main='')
#q=1

#Looking at impact of price prior periods have on consecutive time periods
#PACF (p)
pacf(diff(cotton_tsr),main='')
#p=1. There are 1 partial auto correlation values

# ARIMA Custom(overfit)

cotton_fitR<- Arima(cotton_tsr, order=c(1,1,1))
cotton_fitR

#Check residuals

checkresiduals(cotton_fitR)

#Auto-fit Arima(overfit)

auto_cottonR<- auto.arima(cotton_tsr)
auto_cottonR
checkresiduals(auto_cottonR)

##Forecast Plot

autoplot(forecast::forecast(auto_cottonR, h=12, level=c(80,95)))

##Forecast Custom

autoplot(forecast::forecast(cotton_fitR, h=12, level=c(80,95)))

#Printing Predictions

cotton_predictions <- forecast::forecast(cotton_fitR,h=12)

print(cotton_predictions$mean)

cotton_predictions <- forecast::forecast(auto_cottonR,h=12)

print(cotton_predictions$mean)

```

# GARCH Cotton Modeling
```{r}
# Model Creation
garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(0,0), include.mean = TRUE), distribution.model = "std")
# Fitting Model to Data

cotton_garch <- ugarchfit(spec = garch_model, data = cotton_ts)

print(cotton_garch)

#plot(cotton_garch, which = 1)

coef(cotton_garch)

# Forecasting

horizon <- 3

cotton_forecast_garch <- ugarchforecast(cotton_garch, n.ahead = horizon)

forecast_mean_cotton <- as.numeric(cotton_forecast_garch@forecast$seriesFor)
actual_values_cotton <- as.numeric(window(cotton_ts, start = c(1993, 1)))


plot(cotton_forecast_garch, n.plot = horizon, n.col = 1, plot.type = "single", 
     main = "GARCH Forecast for cotton Prices", ylab = "Price", xlab = "Time") #%>%
lines(cotton_ts[(length(cotton_ts)-horizon+1):length(cotton_ts)], col = "blue")


#Based on signficance. Let's try auto_arimas

garch_model <- ugarchspec(variance.model = list(model = "sGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

cotton_garch2 <- ugarchfit(spec = garch_model, data = cotton_ts)
cotton_garch2

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

cotton_vol <-ts(cotton_garch2@fit$sigma^2,start=c(1993),frequency=12)

#plot(cotton_vol,xlab="",ylab="",main="cotton_Volatility (GARCH[1,1])")

#Exponential GARCH (does not work quite as well)
Egarch_model <- ugarchspec(variance.model = list(model = "eGARCH", 
                                                garchOrder = c(1,1)), 
                                                mean.model = list(armaOrder =
                                                c(1,0), include.mean = TRUE), distribution.model = "std")

cotton_egarch2 <- ugarchfit(spec = garch_model, data = cotton_ts)
cotton_egarch2
coef(cotton_egarch2)

#Time Series based on volatility or Variance based on a standard Garch [1,1] model

ecotton_vol <-ts(cotton_egarch2@fit$sigma^2,start=c(1993),frequency=12)

#plot(ecotton_vol,xlab="",ylab="",main="cotton_Volatility (eGARCH[1,1])")

cor(cotton_vol, ecotton_vol)

ts.plot(cotton_vol,ecotton_vol,col=c("green","red"),xlab="")
legend("topright",legend=c("Standard","Exponential"),col=c("green","red"),lty=c(1,1))
#No difference shown

#GARCH 3

names(cotton_garch2@model)
names(cotton_garch2@fit)
#Variance
cotton_garch_var <- cotton_garch2@fit$var
#Residuals
cotton_garch_res <- (cotton_garch2@fit$residuals)^2

#Plotting residuals and conditional variances
plot(cotton_garch_res, type = "l")
lines(cotton_garch_var, col = "green")

cotton_forecast_garch2 <- ugarchforecast(cotton_garch2, n.ahead = 12)
cotton_forecast_garch2

ug_cotton <- cotton_forecast_garch2@forecast$sigmaFor
plot(ug_cotton, type = "l")

cotton_var_t <- c(tail(cotton_garch_var,20),rep(NA,10))  # gets the last 20 observations
cotton_res_t <- c(tail(cotton_garch_res,20),rep(NA,10))  # gets the last 20 observations
cotton_f <- c(rep(NA,20),(ug_cotton)^2)

plot(cotton_res_t, type = "l") #Residuals
lines(cotton_f, col = "orange") # Predictions 
lines(cotton_var_t, col = "green") #Conditional Forecast
legend("topright", 
       legend = c("Residuals", "Predictions", "Conditional Forecast"), 
       col = c("black", "orange", "green"), 
       lty = c(1, 1, 1), 
       cex = 0.8)

#Plot Predictions
#plot(cotton_forecast_garch2, main = "Forecasted cotton Prices (GARCH(1,1))")


cotton_mean_forecast <- as.numeric(cotton_forecast_garch2@forecast$seriesFor)


# Plot the mean forecasted values with the two confidence intervals

#plot(cotton_forecast_garch2, main = "Forecasted cotton Prices (GARCH(1,1))")


```



```{r}
#ARIMA Models
forecast::accuracy(cotton_fit)
forecast::accuracy(auto_cotton)
forecast::accuracy(cotton_fitR)

AIC(cotton_fit)
BIC(cotton_fit)

AIC(cotton_fitR)
BIC(cotton_fitR)


#GARCH Model

actual_values_cotton <- head(actual_values_cotton, length(cotton_mean_forecast))

mae <- mean(abs(forecast_mean_cotton - actual_values_cotton))
mse <- mean((forecast_mean_cotton - actual_values_cotton)^2)
rmse <- sqrt(mse)

# Print the results
cat(paste("MAE: ", mae, "\n"))
cat(paste("MSE: ", mse, "\n"))
cat(paste("RMSE: ", rmse, "\n"))


#GARCH Model 2
forecast_mean_cotton2 <- as.numeric(cotton_forecast_garch2@forecast$seriesFor)
actual_values_cotton2 <- as.numeric(window(cotton_ts, start = c(1993, 1)))
actual_values_cotton2 <- head(actual_values_cotton2, length(forecast_mean_cotton2))

cotton_mae <- mean(abs(forecast_mean_cotton2 - actual_values_cotton2))
cotton_mse <- mean((forecast_mean_cotton2 - actual_values_cotton2)^2)
cotton_rmse <- sqrt(cotton_mse)
# Print the results
cat(paste("MAE: ", cotton_mae, "\n"))
cat(paste("MSE: ", cotton_mse, "\n"))
cat(paste("RMSE: ", cotton_rmse, "\n"))

cotton_garch
cotton_garch2

```


# EDA Results
```{r}
# There seems to be major economic events that impact the prices of every commodity. These include sharp increases and decreases in prices before a leveling out. However, there does not seem to be significant price changes based on weekday. Commodity pricing did see some sharp changes during the years 2008 to 2012, which deserves additional exploration.

#In general, the 90's showed steady prices of commodities and even were on a bit of downward trend. Things began to shift around 2002. Between 2002 most commodities saw a gradual incline followed by a sharp spike in 2008 again in 2011 and one more time around 2020 and 2022. Some of the common factors of price increase include the declining value of the US dollar, rising energy prices and crop yields. 

#Demand for products has been increasing as the world population increases. Developing countries and markets tend to use more commodities which increases price on global markets. After the 2008 recession, demand increased along with continued currency depreciation leading to price spikes. 

#The current economic situation is unique and has led to another commodity price surge for a number of reasons. High inflation continues to devalue currency and be a increase price. A sharp increase in demand and manufacturing have also impacted price, following covid initiated supply disruptions. Weather and inaccurate forecasting also impacted those price hikes. 

#The biggest industries that use similar commodities as Swire are food, fuel and clothing. A disruption in demand from any one of these will impact commodity prices for Swire. For instance, the fuel industry uses a lot of corn and sugar in their production. This industry is particularly vulnerable to economic events leading to difficulty in price forecasting.

# As I explored the data I realized more and more that there is a great deal of freedom in it and always something additional to look at. I have further questions and plots I'd like to create for this and will continue to add to this during the semester as I keep working on this project. 

#At this point, no ethical concerns were uncovered.

```


# Model Performance Evaluation
```{r}
# The ARIMA models allowed for the most flexibility in parameter selection. I was also able to predict using 30 years of data or just the more recent(3-6 years) pricing data. For the commodities sugar and coffee, using more recent data actually helped improve predictions for future pricing. A possible explanation of this, is that recent data is more relevant to predicting near-future prices. The auto-generated ARIMA models tended to be less accurate and have very poor predictive power. For this reason, hand-selecting P,D and Q values based on correlation and partial-correlation, this led to the best results.

# The ETS models take from more recent data for its predictions. As a result, slicing by recent data does not do much to impact predictions. The predictions were worse than the ARIMA models and the confidence regions were much larger. When compared to the ARIMA and GARCH models, the ETS model had little upside. 

# The GARCH model proved to be extremely valuable in predicting commodity pricing. Commodities are volatile to market changes making it hard to predict prices. The model predicts with this in mind, making it more accurate for financial data. The GARCH models continually predicted market volatility much better than the ARIMA model. It was a little less accurate during regular market flow. 

# Based on prediction errors RMSE, MAE, and the residuals, the ARIMA and GARCH models are the best for prediction. The ARIMA model is valuable to use in tandem with the GARCH models. ARIMA is the easiest model to tune making it a great choice for analysis and building a model with varying levels of confidence. The GARCH model controls for volatility in this specific type of data. This makes it a great choice for predictions in times of uncertainty. My recommendation would be to use both models when making business decisions based on commodity price. 


```


# Model Results and Business Problem
```{r}
# Having accurate predictions of price will help Swire with their business strategies. Knowing the direction price is likely to take, higher or lower, will inform Swire of when to purchase and how much volume to purchase. The ideal being to purchase commodities at the lowest price to maximize margins. The models have proven accurate enough to give direction information several months in advance. The price range within the forecasts looking forward a few months is relatively small. Considering the amount of information these models can give to purchase planning, they provide a great deal of help in solving the business problem. 

```